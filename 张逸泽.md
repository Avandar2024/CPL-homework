<!doctype html><div class="lake-content" typography="classic"><h2 id="WcNfB"><span class="ne-text">必做任务1：面对这个问题，我的思路：</span></h2><ul class="ne-ul"><li id="u81fd689f" data-lake-index-type="0"><span class="ne-text">看B站等视频网站自学（比较有共性/较为普适的问题适合在视频网站上找。不可能看完每个视频，怎么挑选视频？：根据热度和播放量排名，群众的眼睛是雪亮的；也有专门推荐和总结学习视频的视频可以参考）</span></li><li id="ub8b96e30" data-lake-index-type="0"><span class="ne-text">问百度、bing、Google等搜索引擎（搜索结果一大堆，根据标题和提示的部分内容初步筛选哪些可能是我需要的，也可以根据更新时间和点击量做出判断）</span></li><li id="u32e6b2cb" data-lake-index-type="0"><span class="ne-text">问GPT等大模型（用起来挺爽，答案并不一定对，大模型也会捏造事实，也会胡说八道。通常情况下，大模型的输出都太空洞了，我采取的措施是根据它反馈的内容抽取部分关键语句再让其给出更具体/更小分支的答案）</span></li></ul><h2 id="XrZ0A"><span class="ne-text">必做任务2：</span></h2><p id="u61ee0465" class="ne-p"><span class="ne-text">当今时代，搜索能力真太太太重要了！！</span></p><p id="ub267a19e" class="ne-p"><span class="ne-text">思维上的一大跃升</span></p><p id="ue85780d9" class="ne-p"><span class="ne-text">具体一点，搜索引擎的选择、基础搜索语法（限定关键词等）</span></p><p id="u3cf7b744" class="ne-p"><span class="ne-text">它真的能大幅度提升效率，我知道为啥我进行一些搜索的任务花的时间比别人长了</span></p><h2 id="EwU2d"><span class="ne-text">必做任务3：</span></h2><p id="ue24e25aa" class="ne-p"><span class="ne-text">1.不管自己是什么专业，编程能力都十分重要，而且自学又是其中最为重要的一环。根据视频中up的分级，自己现在显然还是一个小白，只会c和python的基本语法和简单程序，但对于数据结构和算法更可以说是一无所知，还有非常非常多的事情需要我去自学。</span></p><p id="uc80d4e51" class="ne-p"><span class="ne-text">2.拆解自己的目标，逐个击破。真正的学习一定是碎片化的，长期的，不断在日常学习生活中刺激的。认识到一万小时定则和坚持的必要性。</span></p><p id="ud1cf337d" class="ne-p"><span class="ne-text">3.不做过于重复的事情，也不做对自己过于困难的事情。如果遇到自己很长时间都没想明白的东西可以先暂时跳过。</span></p><h2 id="zk5Vp"><span class="ne-text">实践任务</span></h2><p id="u45e6ee81" class="ne-p"><span class="ne-text">相比于选择一个分支任务完成，我更想都去尝试一下，这样会对爬虫的认识会更加具体、全面、系统。（毕竟分支一是所有分支的基础，连爬虫是什么的都不知道的话何谈完成后面的任务）</span></p><h3 id="H3iUa"><span class="ne-text">1.什么是爬虫</span></h3><p id="ud9c93337" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">爬虫，简单来说，就是一种自动化的程序或脚本，它能在互联网上自动抓取、收集数据。想象一下，如果你手动在网页上浏览、复制、粘贴信息，那效率肯定很低，而且容易出错。而爬虫就像是一个不知疲倦的“网络小助手”，它会按照你设定的规则，自动访问网页，把里面的内容（比如文字、图片、视频等）抓取下来，保存到你的电脑或者数据库中。（来自大模型）（比较通俗，应该都能看懂）</span></p><h3 id="PjRqx"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">2.爬虫的主要步骤</span></h3><p id="u5e803017" class="ne-p"><strong><span class="ne-text">1.获取网页内容</span></strong><span class="ne-text"> ：类似于用户在浏览器中获取内容，区别在于用程序获得的内容没有渲染步骤，所以看到的内容更加原始。</span></p><p id="ub6cd15b9" class="ne-p"><strong><span class="ne-text">2.解析网页内容</span></strong><span class="ne-text"> ：通过上一个步骤可以获取整个网页的内容，但他太多太全了，很可能不是我们想要的。比如一个商品界面，我们可能只对商品名和价格感兴趣，其他无关信息都不需要，所以需要对内容进行解析，把想要的数据提取出来。</span></p><p id="u752c9280" class="ne-p"><strong><span class="ne-text">3.储存或分析数据</span></strong><span class="ne-text"> ：这一步骤的执行取决于具体需求，例如若是收集数据集，此步骤就是把数据储存进数据库，若是为了分析数据趋势，此步骤就是把数据做成可视化图表，若是为了舆情监控，此步骤就是用AI做文本情绪分析。我们也可以给一串网址（不止一个），让程序一个个去爬取。</span></p><p id="u85229275" class="ne-p"><span class="ne-text"></span></p><p id="ud5144e25" class="ne-p"><span class="ne-text">以下是大模型给的答案（对于新手来说难以理解，可能是因为有太多看不懂的专业名词）：</span></p><ol class="ne-ol"><li id="u0816a54f" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">发送请求</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：爬虫首先向目标网站发送HTTP请求，请求特定的网页内容。通常使用GET或POST方法来获取网页数据。请求可能包含一些额外的参数，如请求头、Cookie等，以便模拟真实的浏览器行为。</span></li><li id="u26cf44b3" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">获取响应</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：服务器接收到请求后，会返回一个响应，这个响应通常包含网页的HTML代码和其他相关信息，如状态码、响应头等。这是爬虫获取网页内容的关键步骤。</span></li><li id="u5bcd8848" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">解析内容</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：爬虫对获取到的网页内容进行解析，提取出需要的信息，如链接、文本、图片等。可以使用解析库（如BeautifulSoup、lxml）或者正则表达式等方式，对获取到的HTML代码进行解析。</span></li><li id="u294d5146" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">存储数据</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：爬虫将提取到的数据存储到本地文件、数据库或者内存中，以备后续处理或展示。存储的方式可以依据具体需求和数据结构来进行选择，常用的存储方式包括存储到文件（如CSV、JSON、Excel）、存储到关系型数据库（如MySQL、PostgreSQL）、存储到非关系型数据库（如Redis、MongoDB）等。</span></li><li id="u804fa1d4" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">跟踪链接</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">（可选）：如果需要爬取整个网站或某个特定领域的内容，爬虫会根据规则或算法，跟踪网页中的链接，继续获取更多的页面内容，形成一个网页抓取的链条。</span></li></ol><h3 id="mFgrw"><span class="ne-text">3.学习内容分解1：HTTP请求（纯理论）</span></h3><p id="ub87d66d7" class="ne-p"><span class="ne-text">学习目的：通过发送HTTP请求来获取网页内容</span></p><h4 id="WDI49"><span class="ne-text">1.概念：</span><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">HTTP，全称超文本传输协议（HyperText Transfer Protocol），是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP是万维网（WWW）的数据通信的基础，在浏览器和服务器之间传输超文本（如HTML文档）。</span></h4><p id="uef63ff6b" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">HTTP的工作方式可以概括为：</span></p><ol class="ne-ol"><li id="uc97aa4cc" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">客户端请求</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：用户在浏览器中输入一个网址或点击一个链接，浏览器会向服务器发送一个HTTP请求。这个请求包含了请求方法（如GET、POST等）、请求的URL、请求头（如User-Agent、Accept等）等信息。</span></li><li id="uc871efa9" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器响应</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：服务器接收到请求后，会处理这个请求，并返回一个HTTP响应。这个响应包含了状态码（如200表示成功、404表示未找到等）、响应头（如Content-Type、Content-Length等）和响应体（如HTML文档、图片等）。</span></li><li id="u8cf7272f" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">浏览器渲染</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：浏览器接收到服务器的响应后，会解析响应体中的内容，并根据需要向服务器请求更多的资源（如CSS、JavaScript、图片等），然后渲染出最终的网页。</span></li></ol><p id="u0a51a7dd" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">需要注意的是，HTTP本身是一个不安全的协议，因为它传输的数据是明文的，容易被窃听和篡改。为了解决这个问题，HTTPS（HTTP Secure）应运而生。HTTPS是在HTTP的基础上加入了SSL/TLS层，提供了加密通信和身份验证的功能，从而保证了数据传输的安全性和完整性。</span></p><h4 id="Fs3qz"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">2.HTTP分类</span></h4><p id="ue4b80020" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732264438522-45a79cb8-2926-41d7-86ef-8db4349a9b70.png" width="569.7803344726562" id="ubb6a788a" class="ne-image"></p><p id="ua2a50e89" class="ne-p"><span class="ne-text">爬虫主要是获取数据，所以主要用GET方法</span></p><h4 id="A1a9V"><span class="ne-text">3.一个完整的HTTP请求</span></h4><p id="u45869256" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732264511939-b22cb4c3-a47f-432a-99d1-48e8a9d2f4b3.png" width="688.7727661132812" id="u9fa46680" class="ne-image"></p><p id="udd3d6e05" class="ne-p"><span class="ne-text">请求行：方法类型+资源路径+协议版本   （资源路径后面可跟查询参数，不同的信息用&amp;分隔）</span></p><p id="uc879fb79" class="ne-p"><span class="ne-text">请求头：给服务器的信息 Host（主机域名）accept（获取类型，*/*代表啥类型都行）</span></p><p id="uf002f9a8" class="ne-p"><span class="ne-text">请求体：客户端传给服务器的其他任意数据，GET方法的请求体一般是空的</span></p><p id="u6b18a09d" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732264822411-61b91a21-cace-41e5-a55a-9b8bcddd722f.png" width="690.7803344726562" id="uc0d413a2" class="ne-image"></p><p id="u57c17b34" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732264890796-5060ebad-a129-4b05-a56e-6573ed982dc3.png" width="685.7803344726562" id="ube463355" class="ne-image"></p><p id="u8a4f35c9" class="ne-p"><span class="ne-text"></span></p><h3 id="H11ii"><span class="ne-text">4.学习内容分解2：python的request库</span></h3><h4 id="d7xxg"><span class="ne-text">学习目的：用python来构建和发送一个HTTP请求<br /></span><span class="ne-text">1.如何安装</span></h4><p id="u1d262438" class="ne-p"><span class="ne-text">懒得手敲了，直接上大模型</span></p><h5 id="ZzgSf"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">一、确保Python已安装</span></h5><p id="u774d0827" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">首先，需要确保计算机上已经安装了Python，并且Python环境变量已经配置正确。可以通过在命令行或终端中输入</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">python --version</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">或</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">python3 --version</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">来检查Python是否安装以及安装的版本。</span></p><h5 id="T1UVN"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">二、打开命令行终端</span></h5><p id="u8ab75449" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">根据你的操作系统，打开相应的命令行工具：</span></p><ul class="ne-ul"><li id="uc9cad05d" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">在Windows上，可以使用命令提示符（CMD）或PowerShell。</span></li><li id="u9e717dfc" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">在macOS或Linux上，可以使用终端（Terminal）。</span></li></ul><h5 id="dpXqG"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">三、使用pip命令安装requests库</span></h5><p id="u312a7c44" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">pip是Python的包管理工具，用于安装和管理Python包。在命令行中输入以下命令来安装requests库：</span></p><ul class="ne-ul"><li id="ub1356e43" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">对于大多数情况（Python 3），可以使用命令：</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">pip install requests</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)"> </span><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">或</span><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)"> </span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">pip3 install requests</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">。</span></li><li id="u4d5b5b41" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果在Linux系统上需要管理员权限，可以使用命令：</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">sudo pip install requests</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">。</span></li></ul><p id="uc7cf790a" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">pip将会从Python包索引（PyPI）下载requests库及其依赖项，并安装到你的Python环境中。这个过程可能需要一些时间，具体取决于网络连接速度和计算机性能。</span></p><h5 id="pm8kZ"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">四、验证安装是否成功</span></h5><p id="u06d5b1ec" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">安装完成后，可以通过以下方式验证requests库是否成功安装：</span></p><ol class="ne-ol"><li id="u2a04adf8" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">打开Python解释器（在命令行或终端中输入</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">python</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">或</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">python3</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">）。</span></li><li id="ud934e57f" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">在Python解释器中输入以下代码：</span></li></ol><pre data-language="python" id="QIDk4" class="ne-codeblock language-python"><code>python复制代码



import requests
print(requests.__version__)</code></pre><ol class="ne-ol"><li id="u6f2d3c4e" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果没有出现错误信息，并且打印出了requests库的版本号，那么说明requests库已经成功安装。</span></li></ol><h5 id="voSZG"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">五、其他安装方法（可选）</span></h5><p id="ued5486e9" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">除了使用pip命令安装外，还有其他几种方法可以安装requests库：</span></p><ol class="ne-ol"><li id="uc11a8365" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">下载源码安装</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：可以从官方网站下载requests模块的源码，解压后进入解压目录，然后使用</span><code class="ne-code"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254); font-size: 13px">python setup.py install</span></code><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">命令进行安装。</span></li><li id="uc877087f" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">使用PyCharm工具安装</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：如果使用的是PyCharm开发工具，可以通过“File”菜单选择“Settings”，在设置页面中选择“Project:项目名”，然后点击“Python Interpreter”。在Python解释器页面中，点击左上角的“+”号，然后输入“requests”，点击“Install Package”即可等待安装完成。</span></li></ol><p id="ud02166c6" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">按照以上步骤操作，你应该能够顺利地在Python中安装并使用requests库。如果在安装过程中遇到任何问题，可以检查网络连接、Python环境配置以及pip版本是否正确。</span></p><p id="u25b8059b" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732265357841-8e5182bf-823b-4ce9-adfb-059e28a9b44a.png" width="521.7803344726562" id="ub68f950e" class="ne-image"></p><p id="u42a64c76" class="ne-p"><br></p><h4 id="VdPTa"><span class="ne-text">2.具体实现</span></h4><p id="u3f2a5ba3" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732265488722-a1ed7198-c6c3-48f1-86ea-65434793cbbf.png" width="1118.1818343391105" id="u34595759" class="ne-image"></p><p id="uff47234f" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732265504427-f8122ca1-b939-482f-b295-4da247ed5d4d.png" width="1070.9091063833107" id="u917be3e2" class="ne-image"></p><p id="u7193be82" class="ne-p"><span class="ne-text"> </span></p><h3 id="KAfmK"><span class="ne-text">5.初步尝试</span></h3><pre data-language="python" id="GEdb0" class="ne-codeblock language-python"><code>import requests

# 豆瓣电影Top 250第一页的URL
url = 'https://movie.douban.com/top250'

# 发送HTTP GET请求
response = requests.get(url)

# 检查请求是否成功
if response.status_code == 200:
# 获取并打印页面源代码
    page_source = response.text
    print(page_source)
else:
    print(f&quot;请求失败，状态码：{response.status_code}&quot;)</code></pre><p id="u5df9a01a" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">这个脚本做了以下几件事：</span></p><ol class="ne-ol"><li id="u7433696d" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">导入requests库。</span></li><li id="u0722d102" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">定义豆瓣电影Top 250第一页的URL。</span></li><li id="ubbde58e8" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">使用requests.get()函数发送HTTP GET请求到该URL。</span></li><li id="uc440035e" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">检查响应的状态码是否为200（表示请求成功）。</span></li><li id="u4f3d723c" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果请求成功，获取响应的文本内容（即页面源代码），并打印出来。</span></li><li id="u4cfebabe" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果请求失败，打印出失败的状态码。</span></li></ol><p id="u215d7ed7" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">然而，豆瓣电影Top 250是分页显示的，每页显示25部电影。要获取所有250部电影的源代码，你需要遍历所有10页。此外，豆瓣可能还采取了反爬虫措施，如动态加载内容、使用JavaScript渲染页面等，这可能导致直接使用requests库无法获取完整的页面内容。</span></p><p id="ua6fb074f" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">为了获取所有页面的内容，你可以修改上面的脚本，使用一个循环来遍历所有页面的URL。但请注意，这样做可能会违反豆瓣的使用条款，并且如果豆瓣检测到频繁的请求，可能会暂时或永久地封禁你的IP地址。</span></p><p id="u22ae33b8" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732265985977-4b5ae27b-53b3-4574-88ef-18b3e2f385ea.png" width="1551.515173933942" id="u000a88c6" class="ne-image"></p><p id="u36f418af" class="ne-p"><strong><span class="ne-text">查询失败原因</span></strong><span class="ne-text">：、</span></p><p id="ubaac4865" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">当使用requests库发送HTTP请求并收到失败的状态码时，可能的原因有多种。以下是一些常见的导致请求失败的原因：</span></p><ol class="ne-ol"><li id="uac4b99ae" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">网络问题</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u9fd9479c" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">你的设备可能无法连接到互联网。</span></li><li id="u9c93682f" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">目标服务器可能无法访问（例如，服务器宕机或维护）。</span></li><li id="ud1e1fd60" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">DNS解析问题可能导致无法找到服务器的IP地址。</span></li></ul></ul><ol start="2" class="ne-ol"><li id="uf26a8830" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">URL错误</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u9f5e96dc" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">你可能输入了错误的URL。</span></li><li id="u97ef04b1" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">URL可能已被更改或删除。</span></li></ul></ul><ol start="3" class="ne-ol"><li id="u4d8002ed" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">HTTP方法不支持</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u27625892" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器可能不支持你使用的HTTP方法（如GET、POST等）。</span></li></ul></ul><ol start="4" class="ne-ol"><li id="u937cd06c" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">请求头问题</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u3b9e9487" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">缺少必要的请求头，如User-Agent，导致服务器拒绝服务。</span></li><li id="uf197b6c0" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">请求头中的信息格式不正确或包含无效字符。</span></li></ul></ul><ol start="5" class="ne-ol"><li id="u4ef4657f" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">重定向问题</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="ud422f171" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器可能返回了一个重定向状态码（如301、302），但requests库没有正确地处理它。</span></li></ul></ul><ol start="6" class="ne-ol"><li id="u09fec592" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">超时</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u5f97b956" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">请求可能由于网络延迟或服务器处理缓慢而超时。</span></li></ul></ul><ol start="7" class="ne-ol"><li id="u68b9350b" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">SSL/TLS证书问题</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="ud87375e8" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果使用的是HTTPS，服务器的SSL/TLS证书可能有问题（如过期、不受信任、域名不匹配等）。</span></li></ul></ul><ol start="8" class="ne-ol"><li id="u65fab739" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">反爬虫机制</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="uddb4620a" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">目标网站可能实施了反爬虫策略，如检查请求频率、User-Agent、Referer、Cookies等。</span></li></ul></ul><ol start="9" class="ne-ol"><li id="uff6822d2" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">HTTP状态码</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u5b2f9e5d" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器可能返回了一个表示错误的HTTP状态码，如404（未找到）、403（禁止访问）、500（服务器内部错误）等。</span></li></ul></ul><ol start="10" class="ne-ol"><li id="ufa823e6a" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">资源限制</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u91b88c52" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器可能由于资源限制（如带宽、CPU、内存等）而拒绝服务。</span></li></ul></ul><ol start="11" class="ne-ol"><li id="uf58fa692" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">IP被封禁</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="ub7544e6b" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果之前发送了过多的请求，你的IP地址可能已被目标网站封禁。</span></li></ul></ul><ol start="12" class="ne-ol"><li id="u194534c0" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">代理或VPN问题</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="u9fb151c1" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">如果你正在使用代理或VPN，它们可能配置不正确或出现故障。</span></li></ul></ul><p id="uc8cfc5a1" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59)">418状态码代表了什么？</span></strong></p><p id="u9ceceb04" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">HTTP状态码418是一个非标准的、具有幽默性质的错误代码，其完整表述通常为“I'm a teapot”（我是一个茶壶）。这个状态码源自1998年的一个愚人节笑话，被写入了一个名为RFC 2324的文档，该文档描述了一个虚构的“超文本咖啡壶控制协议”（HTCPCP）。</span></p><p id="ucb6530f1" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">在这个协议中，HTTP错误418被定义为当客户端尝试让一个咖啡壶执行它不支持的操作（比如冲泡咖啡以外的任何液体）时，咖啡壶应返回的错误代码。虽然这是一个玩笑性质的协议和错误代码，但在一些网络应用和API中，偶尔也会被用作一种幽默或特殊的错误响应。</span></p><p id="u9496a48d" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">具体到你的情况，如果你在使用requests库请求豆瓣电影Top 250页面时收到了418状态码，这很可能意味着：</span></p><ol class="ne-ol"><li id="u1e6e3dc3" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器以幽默的方式回应</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：豆瓣的服务器可能故意返回了这个非标准的状态码，作为一种幽默或特殊的错误处理机制。这通常发生在特定的日期（如愚人节）或针对特定的请求模式。</span></li><li id="u0187535c" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">反爬虫策略</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：豆瓣可能实施了一种反爬虫策略，通过返回非标准的状态码来识别并阻止爬虫程序。在这种情况下，418状态码可能是一个信号，表明你的请求被识别为爬虫行为。</span></li><li id="uc7b7e3ad" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">服务器配置错误或故障</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：虽然不太可能，但也有可能是豆瓣的服务器配置错误或出现了某种故障，导致错误地返回了418状态码。</span></li></ol><p id="u5338f0ba" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">为了解决这个问题，你可以尝试以下步骤：</span></p><ul class="ne-ul"><li id="u5ae57fb6" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">检查请求头</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：确保你的请求头包含了正确的信息，特别是User-Agent，它应该模拟一个正常的浏览器请求。</span></li><li id="u03a59e9f" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">修改请求频率</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：如果你之前发送了过多的请求，尝试降低请求频率，以避免触发豆瓣的反爬虫机制。</span></li><li id="u00e6c28c" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">使用代理或VPN</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：尝试通过代理或VPN发送请求，以绕过可能的IP封禁或地域限制。但请注意，这可能会增加请求被识别为爬虫的风险。</span></li><li id="u83170bb7" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">联系豆瓣客服</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：如果问题持续存在，你可以尝试联系豆瓣的客服或技术支持团队，询问他们是否对请求进行了特殊的处理或限制。</span></li><li id="u2ceab889" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">等待并重试</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：有时，简单地等待一段时间并重试请求就可以解决问题。这可能是因为豆瓣的服务器暂时出现了故障或正在进行维护。</span></li></ul><p id="u05cf830e" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59)"></span></strong></p><p id="u737612b6" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59)">解决方法：</span></strong></p><p id="u036b27c3" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59)">定义请求头，把程序伪装成浏览器（还挺好玩）</span></strong></p><pre data-language="python" id="mCuPn" class="ne-codeblock language-python"><code>import requests

# 豆瓣电影Top 250第一页的URL
url = 'https://movie.douban.com/top250'

# 定义请求头，包括User-Agent
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# 发送HTTP GET请求，并包含请求头
response = requests.get(url, headers=headers)

# 检查请求是否成功
if response.status_code == 200:
    # 获取并打印页面源代码
    page_source = response.text
    print(page_source[:1000])  # 这里只打印前1000个字符作为示例
else:
    print(f&quot;请求失败，状态码：{response.status_code}&quot;)</code></pre><p id="u47959569" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732266323730-1cc78746-b6da-4837-9a2b-5863cc0248e3.png" width="1551.515173933942" id="u141482a1" class="ne-image"></p><p id="u65b87cad" class="ne-p"><span class="ne-text">当然，内容谁都看不懂，这就引出了HTTP的网页结构</span></p><p id="ufe9f9231" class="ne-p"><span class="ne-text">好，我本来想再把HTTP的网页结构粘过来，但这样工作量实在太大了，还是直接跳过吧，跳跃式学习（笑）</span></p><p id="ue23d021d" class="ne-p"><span class="ne-text"></span></p><p id="ue47ebe70" class="ne-p"><span class="ne-text"></span></p><p id="u202e3c0b" class="ne-p"><span class="ne-text">下一步：解析网页内容（具体就是把源码转换为能看懂的信息）</span></p><p id="u02671ac5" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732283951289-33532384-8106-4f0f-a7ce-ec594d8af783.png" width="1551.515173933942" id="u9585d18d" class="ne-image"></p><p id="ua564fbe2" class="ne-p"><br></p><pre data-language="python" id="DhvOb" class="ne-codeblock language-python"><code>import requests
from bs4 import BeautifulSoup

# 定义请求头，伪装成浏览器
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'zh-CN,zh;q=0.9',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Referer': 'https://www.douban.com/',  # 如果有必要，可以加上一个引用页
}

# 定义豆瓣TOP250的URL
base_url = 'https://movie.douban.com/top250'

# 初始化一个空的电影列表
movies = []

# 抓取每一页的数据，TOP250是分页显示的，每页25个
for start in range(0, 250, 25):
    url = f'{base_url}?start={start}&amp;filter='
    response = requests.get(url, headers=headers)
    response.raise_for_status()  # 检查请求是否成功

    soup = BeautifulSoup(response.text, 'html.parser')

    # 查找电影信息
    movie_items = soup.find_all('div', class_='item')

    for item in movie_items:
        title_tag = item.find('span', class_='title')
        rating_tag = item.find('span', class_='rating_num')

        title = title_tag.get_text() if title_tag else 'N/A'
        rating = rating_tag.get_text() if rating_tag else 'N/A'

        movies.append({'title': title, 'rating': rating})

# 打印前10部电影的标题和评分
for i, movie in enumerate(movies[:10]):
    print(f'{i+1}. 标题: {movie[&quot;title&quot;]}, 评分: {movie[&quot;rating&quot;]}')</code></pre><p id="ua89054c1" class="ne-p"><span class="ne-text">结果：没有任何输出，失败。	</span></p><p id="u53694325" class="ne-p"><span class="ne-text">尝试2</span></p><pre data-language="python" id="rB2KU" class="ne-codeblock language-python"><code>import requests
from bs4 import BeautifulSoup

headers = {
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36&quot;
}
for start_num in range(0, 250, 25):
    response = requests.get(f&quot;https://movie.douban.com/top250?start={start_num}&quot;, headers=headers)
    html = response.text
    soup = BeautifulSoup(html, &quot;html.parser&quot;)
    all_titles = soup.findAll(&quot;span&quot;, attrs={&quot;class&quot;: &quot;title&quot;})
    for title in all_titles:
        title_string = title.string
        if &quot;/&quot; not in title_string:
            print(title_string)
</code></pre><p id="u2f65aaa4" class="ne-p"><span class="ne-text">成功。</span><img src="https://cdn.nlark.com/yuque/0/2024/png/47021233/1732284777372-626a6dd3-d62a-49ac-9c0d-0209c77db328.png" width="1551.515173933942" id="ue79c1b02" class="ne-image"></p><p id="u638c1863" class="ne-p"><span class="ne-text">总结教训：AI的产出并不一定比开源的资源强多少。</span></p><h3 id="b0uF9"><span class="ne-text">6.一些其他分支</span></h3><p id="u22822769" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59)">Python的常用爬虫工具及参考代码</span></strong></p><h4 id="ilPKz"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">一、主要工具</span></h4><ol class="ne-ol"><li id="u2fcbc5c1" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">Requests</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></li></ol><ul class="ne-list-wrap"><ul ne-level="1" class="ne-ul"><li id="uf5d8b836" data-lake-index-type="0"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">功能：Python中最流行的HTTP请求库之一，简洁易用，支持各种请求方式。</span></li></ul></ul><span style="margin-left: 2em"><pre data-language="python" id="MuncJ" class="ne-codeblock language-python"><code>import requests
url = 'https://example.com'
response = requests.get(url)
print(response.text)</code></pre></span><p id="u3d644012" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">BeautifulSoup</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></p><ul class="ne-ul"><li id="u8b4552cf" data-lake-index-type="0" style="text-align: left"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">功能：用于解析HTML和XML文档的Python库，能够从混乱的HTML代码中提取所需数据。</span></li><li id="u8e05d190" data-lake-index-type="0" style="text-align: left"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">参考代码（与Requests结合使用）：</span></li></ul><pre data-language="python" id="rGV4O" class="ne-codeblock language-python"><code>from bs4 import BeautifulSoup
import requests
url = 'https://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
print(soup.prettify())  # 美化HTML输出</code></pre><p id="u6d148ef5" class="ne-p"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">Scrapy</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：</span></p><ul class="ne-ul"><li id="u014240dd" data-lake-index-type="0" style="text-align: left"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">功能：一个强大的Python爬虫框架，集合了请求、解析、存储等功能于一身，具有高度可扩展性和定制性。</span></li></ul><pre data-language="python" id="sj0RC" class="ne-codeblock language-python"><code># 在Scrapy项目中定义的item.py文件
import scrapy

class MyItem(scrapy.Item):
    title = scrapy.Field()
    url = scrapy.Field()
    description = scrapy.Field()

# 在Scrapy项目中定义的spider文件（例如my_spider.py）
import scrapy

class MySpider(scrapy.Spider):
    name = 'my_spider'
    start_urls = ['https://example.com']

    def parse(self, response):
        for item in response.css('div.item'):
            yield {
                'title': item.css('h2.title::text').get(),
                'url': item.css('a::attr(href)').get(),
                'description': item.css('div.description::text').get(),
            }</code></pre><h4 id="k5Fnf"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">二、其他工具</span></h4><ul class="ne-ul"><li id="uf98cfe5a" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">PySocks</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：用于Python的代理库，支持多种代理协议，有助于应对反爬虫措施。</span></li><li id="ua03890c0" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">Tesseract-OCR</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：开源的OCR引擎，用于识别图像中的文字，可用于处理验证码等。</span></li><li id="uaae16342" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">Celery</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：分布式任务队列，可用于实现爬虫的异步任务管理，提高爬虫效率和稳定性。</span></li><li id="ube0f625e" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">logging</span></strong><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">：Python内置的日志记录模块，可用于记录爬虫运行过程中的各种日志信息，便于跟踪和排查问题。</span></li></ul><h4 id="GjS41"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">三、综合示例</span></h4><p id="uc964cedd" class="ne-p"><span class="ne-text" style="color: rgb(5, 7, 59); background-color: rgb(253, 253, 254)">以下是一个综合使用Requests、BeautifulSoup和PyMongo的爬虫示例，用于爬取一个网页上的所有链接并存储到MongoDB中：</span></p><pre data-language="python" id="zymVf" class="ne-codeblock language-python"><code>import requests
from bs4 import BeautifulSoup
from pymongo import MongoClient

url = 'https://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

client = MongoClient('localhost', 27017)
db = client['mydatabase']
collection = db['links']

links = []
for a_tag in soup.find_all('a', href=True):
    links.append({'url': a_tag['href'], 'text': a_tag.text})

collection.insert_many(links)

print(f&quot;Inserted {len(links)} links into the database.&quot;)</code></pre><h2 id="oY4Jw"><span class="ne-text">总结：</span></h2><p id="ubc627abc" class="ne-p"><span class="ne-text">1.我这周大概先花了3-4个小时把python从0开始速通了一遍，从最基础的字面量，到之后的列表、循环、函数、字典，再到后面面向对象编程的类等等等等，虽然很耗时间，也不太符合CAC所提倡的跳跃式学习，但我觉得这个早晚都得学，不如第一次学的明白一点，不然后面用到py的时候看到一个关键词都不明白是什么意思。</span></p><p id="u86e95050" class="ne-p"><span class="ne-text">2.有关爬虫，我大概是找了一个b站教程跟着做，其实实现一个爬虫程序真的十分简单，大模型可以直接吐给你全部的代码，你只需要ctrl c+v，但要理解其中的原理，明白具体实现的步骤，每一行代码都代表着什么，这并不是几个小时就能完全搞明白的。这看似又与所谓跳跃式学习不符了，但还是有一股神秘力量强迫我去搞明白每一步的原理（）。</span></p><p id="u07f96b49" class="ne-p"><span class="ne-text">3.最后一点疑问，CAC是根据什么标准给我们布置任务的？（理性思考），在CAC给我们推荐的b站编程学习路线中，up主的观点是学习完一门语言后进行数据结构与算法的学习，为何CAC不能将这个看似更为合理的编程学习路径作为我们社团的基本路线？至少我现在即使已经拿出很长时间（大概1-2h）去接触爬虫，但对其仍旧是一知半解，可能我还是一种没有完全转变过来的中学生的学习思维hhh</span></p><p id="u96b64f8e" class="ne-p"><span class="ne-text">4.虽然在跳跃式学习中遇事不决就去问大模型，但我们从中提升了什么？单纯是信息检索能力嘛？大模型会替代我们的思考吗？这样以后公司招聘是不是只要找一个”善于使用大模型或者擅长信息检索“的人就可以了hhhh？（一点好奇）</span></p><p id="u2e238af1" class="ne-p"><span class="ne-text"></span></p><p id="uc63f5a36" class="ne-p"><span class="ne-text">好吧，总结是我在完成任务之前写的，虽然现在好像也没有真正完成任务，我现在已经彻底向跳跃式学习屈服了，不然工作量实在是太太太大了，尤其是对我这种刚会python没几天的小白。</span></p></div>
<!doctype html><div class="lake-content" typography="classic"><h3 id="UiD4p"><span class="ne-text">必做任务1</span></h3><p id="uc3a9ff97" class="ne-p"><span class="ne-text">我的思路是：</span></p><p id="u11f174d6" class="ne-p"><span class="ne-text">明确需要的信息类型，确定使用的工具和平台，使用恰当的语言，综合比较分析检索到的信息</span></p><p id="u0d3d2c32" class="ne-p"><span class="ne-text">具体方法可以有：问身边的大佬，ai，浏览器，视频网站及社团第一周的分支任务文档等</span></p><p id="u44a52017" class="ne-p"><span class="ne-text">了解方法后自行尝试，体验是否找到需要且合适的信息，甚至能获得一些其他拓展信息</span></p><p id="u85b4348b" class="ne-p"><span class="ne-text">任务耗时：10分钟</span></p><h3 id="EW4OH"><span class="ne-text">必做任务2</span></h3><p id="u0522d62b" class="ne-p"><span class="ne-text">我的感受是：</span></p><p id="u34e4c43f" class="ne-p"><span class="ne-text">我之前用的方法效率确实低，想提升效率看来得要科学上网</span><span id="dN1Mg"></span></p><p id="u04bfe4e5" class="ne-p"><span class="ne-text">总结一下视频内容：</span></p><p id="u659cb35d" class="ne-p"><span class="ne-text">搜信息咨询：选择信息渠道，掌握基础搜索语法，直奔信息源头</span></p><p id="u8a3604ab" class="ne-p"><span class="ne-text">搜知识技能：谷歌+YouTube，考虑载体和目的（了解、学习、创作），垂类社群、聚合网址</span></p><p id="ue74bad8b" class="ne-p"><span class="ne-text">搜素材文件：谷歌上找网站（国外老哥就喜欢总结这些，高中英语阅读A片也有好多是这类）</span></p><p id="ud585f728" class="ne-p"><span class="ne-text">搜工具网站：在线工具&gt;下载软件&gt;插件   xxx需求+online</span></p><p id="uf8c5f807" class="ne-p"><img src="https://cdn.nlark.com/yuque/0/2024/png/49722704/1732287705178-635603e1-a772-45a6-a6e0-5fc2db57df7f.png" width="1669" id="u2a7f4c57" class="ne-image"></p><p id="u47e18708" class="ne-p"><span class="ne-text">新型：搜索+学习、搜索+创作、AI</span></p><p id="uabf74f48" class="ne-p"><span class="ne-text">感悟最深的一句话：</span><span class="ne-text" style="background-color: #FBDE28; color: #1DC0C9">搜索是因为你要做的事有人做过且做的比你好，你要做的事是搜到他，学习他，利用它，劈开他，超过他，打破信息差</span></p><p id="udd678fa2" class="ne-p"><span class="ne-text">任务耗时：50分钟（二倍速）</span></p><h3 id="UDYiT"><span class="ne-text">必做任务3</span></h3><p id="u29172084" class="ne-p"><span class="ne-text">我的感受是：</span></p><p id="u6836235d" class="ne-p"><span class="ne-text"> 编程不止是学校的一门课程，它是创造出一个“规则世界”，实现一定目的，需要动手实践和渐进式训练（平滑提升难度，长时间+刻意，拆解目标逐个击破），考验我们局部和系统的眼光，知道自己的目的提供内驱力，因为这是一门需要自学的学问，而且需要细水长流，</span><span class="ne-text" style="background-color: #FBDE28; color: #1DC0C9">大多数人都会高估自己在短时间内学习的效率但是低估了长时间积累的力量</span><span class="ne-text">，还需要学习多种语言避免思维固化，向大佬学习（如Peter Norvig）</span></p><p id="uef887d3b" class="ne-p"><span class="ne-text" style="background-color: #FBDE28; color: #1DC0C9"></span></p><p id="ue68920e8" class="ne-p"><span class="ne-text">任务耗时：20分钟</span></p><h3 id="boDqP"><span class="ne-text">必做任务4</span></h3><p id="u2be66e5f" class="ne-p"><span class="ne-text">我学习了：</span></p><p id="u9744044b" class="ne-p"><span class="ne-text">参考框架学到第八章（虽然好多是之前学过的）</span></p><p id="uf12b860c" class="ne-p"><span class="ne-text">网页一些基本原理（没太懂）和非常基础的爬虫</span></p><p id="u01f24556" class="ne-p"><span class="ne-text">爬虫程序用于自动从互联网上抓取网页内容，基本原理为</span></p><ol data-index-type="true" class="ne-ol"><li id="u9847dec0" data-lake-index-type="true"><span class="ne-text">发送请求</span><span class="ne-text">：</span></li></ol><p id="uf24053db" class="ne-p"><span class="ne-text">爬虫程序首先向目标网站发送HTTP请求（即客户端（比如网页浏览器）向服务器请求数据的一种方式），通常是GET请求，以获取网页内容。</span></p><ol start="2" data-index-type="true" class="ne-ol"><li id="u4b1f96d6" data-lake-index-type="true"><span class="ne-text">接收响应</span><span class="ne-text">：</span></li></ol><p id="ue997a0db" class="ne-p"><span class="ne-text">网站服务器接收到请求后，会处理请求并返回相应的响应。这个响应通常包含网页的HTML代码（构建网页的程序）。</span></p><ol start="3" data-index-type="true" class="ne-ol"><li id="u167e7cb0" data-lake-index-type="true"><span class="ne-text">解析内容、数据提取：</span></li></ol><p id="u805011d8" class="ne-p"><span class="ne-text">程序接收到响应后，需要解析这些HTML代码以提取有用的信息。解析完成后，爬虫程序根据预设的规则提取所需的数据。</span></p><ol start="4" data-index-type="true" class="ne-ol"><li id="uca046047" data-lake-index-type="true"><span class="ne-text">存储数据：</span></li></ol><p id="ud9d38a83" class="ne-p"><span class="ne-text">即保存在需要的地方</span></p><ol start="5" data-index-type="true" class="ne-ol"><li id="u310002f2" data-lake-index-type="true"><span class="ne-text">保证成功率需要的：</span></li></ol><p id="ufd3f836c" class="ne-p"><span class="ne-text">遵循Robots协议：就是不给爬的别爬。</span></p><p id="u3710589c" class="ne-p"><span class="ne-text">用户代理：为了模拟真实用户的浏览器行为，爬虫通常会设置用户代理（User-Agent），以避免被网站识别为爬虫。</span></p><p id="u82bc934a" class="ne-p"><span class="ne-text">速率限制：为了避免对目标网站服务器造成过大压力，爬虫程序通常会限制请求的速率。</span></p><ol start="6" data-index-type="true" class="ne-ol"><li id="u6ee1e1ef" data-lake-index-type="true"><span class="ne-text">处理特殊情况：</span></li></ol><p id="ube829c15" class="ne-p"><span class="ne-text">爬虫需要能够处理HTTP重定向和错误响应，如404（页面未找到）或503（服务不可用）和网络错误、超时等。</span></p><ol start="7" data-index-type="true" class="ne-ol"><li id="u66730c99" data-lake-index-type="true"><span class="ne-text">深度优先或广度优先</span><span class="ne-text">：</span></li></ol><p id="u81753948" class="ne-p"><span class="ne-text">爬虫可以采用深度优先或广度优先的策略来遍历网站链接，这取决于爬取的目标和策略。</span></p><ol start="8" data-index-type="true" class="ne-ol"><li id="u7526206f" data-lake-index-type="true"><span class="ne-text">异步处理</span><span class="ne-text">：</span></li></ol><p id="u7ff96dcb" class="ne-p"><span class="ne-text">对于需要同时处理多个请求的爬虫，可以使用异步编程技术来提高效率。（不太懂）</span></p><ol start="9" data-index-type="true" class="ne-ol"><li id="u38858a7e" data-lake-index-type="true"><span class="ne-text">数据清洗和去重</span><span class="ne-text">：</span></li></ol><p id="u81eb7b9f" class="ne-p"><span class="ne-text">提取的数据可能包含重复或不完整的信息，爬虫程序需要进行数据清洗和去重。（完全不懂）</span></p><ol start="10" data-index-type="true" class="ne-ol"><li id="u369796c2" data-lake-index-type="true"><span class="ne-text">动态内容处理</span><span class="ne-text">：</span></li></ol><p id="u92957027" class="ne-p"><span class="ne-text">有些网站的内容是通过JavaScript动态加载的，爬虫可能需要使用如Selenium或Puppeteer等工具来处理这些动态内容。</span></p><p id="u74dccdc8" class="ne-p"><span class="ne-text">最后无论是ai还是网课都指出爬虫程序的设计和实现需要考虑法律和道德问题，确保遵守相关法律法规，尊重网站的版权和隐私政策，否则会出现爬虫：从入门到入狱的情况。</span></p><p id="u829218a1" class="ne-p"><span class="ne-text">任务耗时：40分钟</span></p><h3 id="eTKut"><span class="ne-text">分支任务：</span></h3><h4 id="zivjw"><span class="ne-text">我选择完成：</span></h4><article class="lake-columns" style="display: flex"><article class="lake-column-item" style="flex: 0.33333333000000004"><ul class="ne-tl"><li id="uc4310cb5" data-lake-index-type="0"><input type="checkbox"><span class="ne-text">分支任务1</span></li><li checked="true" id="u3a738b00" data-lake-index-type="0"><input type="checkbox" checked="true"><span class="ne-text">分支任务2</span></li></ul></article><article class="lake-column-item" style="flex: 0.33333333000000004"><ul class="ne-tl"><li id="u4dfcf3ee" data-lake-index-type="0"><input type="checkbox"><span class="ne-text">分支任务3</span></li><li id="ub67fd927" data-lake-index-type="0"><input type="checkbox"><span class="ne-text">分支任务4</span></li></ul></article><article class="lake-column-item" style="flex: 0.33333333000000004"><ul class="ne-tl"><li id="u566fa63f" data-lake-index-type="0"><input type="checkbox"><span class="ne-text">分支任务5</span></li><li id="ud8d6b74f" data-lake-index-type="0"><input type="checkbox"><span class="ne-text">分支任务6</span></li></ul></article></article><h4 id="nr7EL"><span class="ne-text">任务文档：</span></h4><p id="u19f81207" class="ne-p"><span class="ne-text">工具：kimi、知乎、b站、bing、bilibili</span></p><p id="ue470882d" class="ne-p"><span class="ne-text">搜索关键词即：&quot;python 爬虫 库&quot;，效率和质量已经很高（部分专业名词需要额外搜索）</span></p><h5 id="St1Hv"><span class="ne-text">各种库</span></h5><ol class="ne-ol"><li id="u455bc300" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(25, 27, 31)">请求库</span></strong><span class="ne-text" style="color: rgb(25, 27, 31)">：实现 HTTP 请求操作</span></li></ol><ul data-index-type="true" class="ne-ul"><li id="u2f7b7f2e" data-lake-index-type="true"><span class="ne-text">urllib：一系列用于操作URL的功能。</span></li><li id="ua58c1bc8" data-lake-index-type="true"><span class="ne-text">requests：</span><span class="ne-text">基于 urllib 编写的，阻塞式 HTTP 请求库，发出一个请求，一直等待服务器响应后，程序才能进行下一步处理。</span></li><li id="ua3458140" data-lake-index-type="true"><span class="ne-text">selenium：</span><span class="ne-text">自动化测试工具。一个调用浏览器的 driver，通过这个库你可以直接调用浏览器完成某些操作，比如输入验证码。</span></li><li id="ud0d309ac" data-lake-index-type="true"><span class="ne-text">aiohttp：基于 asyncio 实现的 HTTP 框架。异步操作借助于 async/await 关键字，使用异步库进行数据抓取，可以大大提高效率。</span></li></ul><ol start="2" class="ne-ol"><li id="u25e2c5fe" data-lake-index-type="0"><strong><span class="ne-text">解析库</span></strong><span class="ne-text">：从网页中提取信息</span></li></ol><ul data-index-type="true" class="ne-ul"><li id="u9c9a1f1a" data-lake-index-type="true"><span class="ne-text">beautifulsoup：html 和 XML 的解析,从网页中提取信息，同时拥有强大的API和多样解析方式。</span></li><li id="u09edb2fc" data-lake-index-type="true"><span class="ne-text">pyquery：</span><span class="ne-text">jQuery 的 Python 实现，能够以 jQuery 的语法来操作解析 HTML 文档，易用性和解析速度都很好。</span></li><li id="u6c46461e" data-lake-index-type="true"><span class="ne-text">lxml：</span><span class="ne-text">支持HTML和XML的解析，支持XPath解析方式，而且解析效率非常高。</span></li><li id="uca671ad3" data-lake-index-type="true"><span class="ne-text">tesserocr：一个 OCR 库，在遇到验证码（图形验证码为主）的时候，可直接用 OCR 进行识别。</span></li></ul><ol start="3" class="ne-ol"><li id="ua767339c" data-lake-index-type="0"><strong><span class="ne-text">存储库</span></strong><span class="ne-text">：Python 与数据库交互</span></li></ol><ul data-index-type="true" class="ne-ul"><li id="u4ae33e41" data-lake-index-type="true"><span class="ne-text">pymysql：一个纯 Python 实现的 MySQL 客户端操作库。</span></li><li id="u93f2d490" data-lake-index-type="true"><span class="ne-text">pymongo：一个用于直接连接 mongodb 数据库进行查询操作的库。</span></li><li id="u4cc077be" data-lake-index-type="true"><span class="ne-text">redisdump：</span><span class="ne-text">一个用于 redis 数据导入/导出的工具。基于 ruby 实现的，因此使用它，需要先安装 Ruby。</span></li></ul><ol start="4" class="ne-ol"><li id="uee9be7ae" data-lake-index-type="0"><strong><span class="ne-text">爬虫框架</span></strong></li></ol><ul data-index-type="true" class="ne-ul"><li id="u76e80a9e" data-lake-index-type="true"><span class="ne-text">Scrapy：很强大的爬虫框架，可以满足简单的页面爬取（比如可以明确获知url pattern的情况）。用这个框架可以轻松爬下来如亚马逊商品信息之类的数据。但是对于稍微复杂一点的页面，如 weibo 的页面信息，这个框架就满足不了需求了。</span></li><li id="ud351652b" data-lake-index-type="true"><span class="ne-text">Crawley：高速爬取对应网站的内容，支持关系和非关系数据库，数据可以导出为 JSON、XML 等。</span></li><li id="ud037524c" data-lake-index-type="true"><span class="ne-text">Portia：</span><span class="ne-text">可视化爬取网页内容。</span></li><li id="u557331ba" data-lake-index-type="true"><span class="ne-text">newspaper：提取新闻、文章以及内容分析。</span></li><li id="u2e37b478" data-lake-index-type="true"><span class="ne-text">python-goose：</span><span class="ne-text">java 写的文章提取工具。</span></li><li id="u8bf5187f" data-lake-index-type="true"><span class="ne-text">cola：</span><span class="ne-text">一个分布式爬虫框架。项目整体设计有点糟，模块间耦合度较高。</span></li></ul><ol start="5" class="ne-ol"><li id="u305088c2" data-lake-index-type="0"><strong><span class="ne-text">Web 框架库</span></strong><span class="ne-text">（用于数据展示）</span></li></ol><ul data-index-type="true" class="ne-ul"><li id="u2c66f8d3" data-lake-index-type="true"><span class="ne-text">flask：轻量级的 web 服务程序，简单，易用，灵活，主要来做一些 API 服务。做代理时可能会用到。</span></li><li id="ua3ed3821" data-lake-index-type="true"><span class="ne-text">django：一个 web 服务器框架，提供了一个完整的后台管理，引擎、接口等，使用它可做一个完整网站。</span></li></ul><h5 id="WBr0I"><span class="ne-text">库使用实例</span></h5><ol class="ne-ol"><li id="u7170aca7" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(6, 6, 7); font-size: 14px">Requests</span></strong><span class="ne-text" style="color: rgb(6, 6, 7); font-size: 14px">：发送HTTP请求</span></li></ol><pre data-language="python" id="rN6E7" class="ne-codeblock language-python"><code>import requests

# 发送GET请求
response = requests.get('https://www.example.com')
# 输出状态码
print(response.status_code)
# 输出网页内容
print(response.text)</code></pre><ol start="2" class="ne-ol"><li id="u9c2283ee" data-lake-index-type="0"><strong><span class="ne-text" style="color: rgb(6, 6, 7); font-size: 14px">BeautifulSoup</span></strong><span class="ne-text" style="color: rgb(6, 6, 7); font-size: 14px">（bs4）：解析HTML和XML文档，从网页中提取所需的数据</span></li></ol><pre data-language="python" id="St5Et" class="ne-codeblock language-python"><code>from bs4 import BeautifulSoup
import requests

response = requests.get('https://www.example.com')
soup = BeautifulSoup(response.text, 'html.parser')#使用内置解析器将HTML内容解析成一个对象soup
# 提取网页标题
title = soup.title.string
print(f&quot;网页标题:{title}&quot;)
# 提取所有链接
for link in soup.find_all('a'):#&lt;a&gt;为HTML中表示超链接的标签
    print(link.get('href'))#提取a元素的href属性值
                           #链接的表示为&lt;a href=&quot;xxx&quot;&gt;...&lt;/a&gt; 获取的即为xxx（网址或文件地址）</code></pre><h5 id="cs3CS"><span class="ne-text">实例展示</span></h5><div id="GZ4mS" class="ne-thirdparty"><a href="https://player.bilibili.com/player.html?bvid=BV1t14y1H7Lw&amp;t=122.9&amp;autoplay=0">https://player.bilibili.com/player.html?bvid=BV1t14y1H7Lw&amp;t=122.9&amp;autoplay=0</a></div><p id="u3746c06a" class="ne-p"><span class="ne-text">（9号的活动请假了，不知道具体有什么其他要求不）</span></p><h4 id="leXWt"><span class="ne-text">任务耗时：</span></h4><p id="u0a0c294c" class="ne-p"><span class="ne-text">60分钟</span></p><h3 id="fHddQ"><span class="ne-text">本周活动情绪反馈</span></h3><p id="u822f919e" class="ne-p"><span class="ne-text">（可阐述你的心得、体会、槽点、经验、感受...）</span></p><p id="uf856d2e3" class="ne-p"><span class="ne-text">任务有点多，让ddl党压力很大，下次一定要碎片化学习</span><span class="ne-text">😪</span></p><p id="u77f22a1d" class="ne-p"><span class="ne-text">实践任务比较新颖，目前爬虫程序还是勉强理解简单代码但自己还不太会写，可惜没时间去挑战一下更难的任务，下次一定要碎片化学习</span><span class="ne-text">😴</span></p><p id="u66a5a876" class="ne-p"><span class="ne-text">下次一定</span><span class="ne-text">💦</span></p><p id="u1b2133cd" class="ne-p"><br></p></div>